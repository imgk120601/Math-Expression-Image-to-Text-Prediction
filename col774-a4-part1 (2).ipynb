{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63599,"databundleVersionId":6947127,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision #installing pytorch framework","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-29T09:03:49.890748Z","iopub.execute_input":"2023-11-29T09:03:49.891350Z","iopub.status.idle":"2023-11-29T09:04:06.865663Z","shell.execute_reply.started":"2023-11-29T09:03:49.891316Z","shell.execute_reply":"2023-11-29T09:04:06.864141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pillow","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:06.869259Z","iopub.execute_input":"2023-11-29T09:04:06.870691Z","iopub.status.idle":"2023-11-29T09:04:21.019308Z","shell.execute_reply.started":"2023-11-29T09:04:06.870622Z","shell.execute_reply":"2023-11-29T09:04:21.017388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv_path=\"/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/HandwrittenData/train_hw.csv\"\n#train_csv_path='/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/SyntheticData/train.csv'\nimage_path='/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/SyntheticData/images'","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:21.021090Z","iopub.execute_input":"2023-11-29T09:04:21.021454Z","iopub.status.idle":"2023-11-29T09:04:21.028207Z","shell.execute_reply.started":"2023-11-29T09:04:21.021420Z","shell.execute_reply":"2023-11-29T09:04:21.026775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport csv\nfrom PIL import Image\nimport IPython.display as display\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:21.031112Z","iopub.execute_input":"2023-11-29T09:04:21.031510Z","iopub.status.idle":"2023-11-29T09:04:25.325164Z","shell.execute_reply.started":"2023-11-29T09:04:21.031479Z","shell.execute_reply":"2023-11-29T09:04:25.323491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_path = train_csv_path\ni=0\nwith open(csv_path, 'r') as file:\n    csv_reader = csv.reader(file)\n     \n    for row in csv_reader:\n        if(i>=0):\n            print(row)    \n        i=i+1\n        if(i>=4):\n            break\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.327121Z","iopub.execute_input":"2023-11-29T09:04:25.327786Z","iopub.status.idle":"2023-11-29T09:04:25.356370Z","shell.execute_reply.started":"2023-11-29T09:04:25.327745Z","shell.execute_reply":"2023-11-29T09:04:25.354707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_string = \"This is a sample string for tokenization\"\n# Split the string into tokens\ntokens = input_string.split(' ')\n# Print the tokens\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.358657Z","iopub.execute_input":"2023-11-29T09:04:25.359212Z","iopub.status.idle":"2023-11-29T09:04:25.372580Z","shell.execute_reply.started":"2023-11-29T09:04:25.359166Z","shell.execute_reply":"2023-11-29T09:04:25.370690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**vocab**","metadata":{}},{"cell_type":"code","source":"formula_to_tokens={}#formulat number to token dictionary\ntokens_set=set()#all unique tokens\n#spliting making formula into token(.spllit(\" \")): making all theeir length same by adding <PAD> token , also adding\n#<SOS> start and end <EOS> token also\ncsv_path = train_csv_path\ni=0\nmax_length=0\nwith open(csv_path, 'r') as file:\n    csv_reader = csv.reader(file)\n     \n    for row in csv_reader:\n        if(i>0):\n            tokens=row[1].split(' ')\n            tokens_set |= set(tokens)\n            \n            #formula_to_token[i]=tokens\n            max_length= max(max_length, len(tokens))\n            #print(i,len(tokens))\n        i=i+1\n\ntokens_set.add(\"<PAD>\")\ntokens_set.add(\"<SOS>\")\ntokens_set.add(\"<EOS>\")\ntokens_idx = {value: idx for idx, value in enumerate(tokens_set)}\nprint(tokens_idx)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.375250Z","iopub.execute_input":"2023-11-29T09:04:25.376160Z","iopub.status.idle":"2023-11-29T09:04:25.441378Z","shell.execute_reply.started":"2023-11-29T09:04:25.376112Z","shell.execute_reply":"2023-11-29T09:04:25.440213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokens_idx[\"<EOS>\"])\nprint(tokens_idx[\"<SOS>\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.442958Z","iopub.execute_input":"2023-11-29T09:04:25.443866Z","iopub.status.idle":"2023-11-29T09:04:25.450964Z","shell.execute_reply.started":"2023-11-29T09:04:25.443808Z","shell.execute_reply":"2023-11-29T09:04:25.449693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=0\nwith open(csv_path, 'r') as file:\n    csv_reader = csv.reader(file)\n     \n    for row in csv_reader:\n        #print(i)\n        if(i>0):\n            tokens=row[1].split(' ')\n            tokens = [tokens_idx[token] for token in tokens]\n            while(len(tokens)<max_length):\n                tokens.append(tokens_idx[\"<PAD>\"])\n            tokens.insert(0,tokens_idx[\"<SOS>\"] )\n            tokens.append(tokens_idx[\"<EOS>\"])\n            formula_to_tokens[i-1]=tokens\n            #max_length= max(max_length, len(tokens))\n            #print(\"hi\")\n            #print(i,tokens)\n        i=i+1\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.452915Z","iopub.execute_input":"2023-11-29T09:04:25.453694Z","iopub.status.idle":"2023-11-29T09:04:25.824098Z","shell.execute_reply.started":"2023-11-29T09:04:25.453645Z","shell.execute_reply":"2023-11-29T09:04:25.822298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def formula_to_token(formula):\n    tokens=formula.split(' ')\n    tokens = [tokens_idx[token] for token in tokens]\n    while(len(tokens)<max_length):\n            tokens.append(tokens_idx[\"<PAD>\"])\n    tokens.insert(0,tokens_idx[\"<SOS>\"] )\n    tokens.append(tokens_idx[\"<EOS>\"])\n    return tokens\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.831751Z","iopub.execute_input":"2023-11-29T09:04:25.832247Z","iopub.status.idle":"2023-11-29T09:04:25.839816Z","shell.execute_reply.started":"2023-11-29T09:04:25.832210Z","shell.execute_reply":"2023-11-29T09:04:25.838669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(formula_to_token(\"$\") )","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.841348Z","iopub.execute_input":"2023-11-29T09:04:25.842493Z","iopub.status.idle":"2023-11-29T09:04:25.855072Z","shell.execute_reply.started":"2023-11-29T09:04:25.842446Z","shell.execute_reply":"2023-11-29T09:04:25.854030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(max_length)\n# print(formula_to_tokens)\n# print(\" \")\n# print(tokens_set)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.856773Z","iopub.execute_input":"2023-11-29T09:04:25.857436Z","iopub.status.idle":"2023-11-29T09:04:25.867234Z","shell.execute_reply.started":"2023-11-29T09:04:25.857396Z","shell.execute_reply":"2023-11-29T09:04:25.865810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\ndef preprocess(image_path):\n    # Read the image using PIL\n    img = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n    \n    # Resize the image to 224x224\n    img_resized = img.resize((224, 224))\n\n    # Create R, G, B channels by duplicating the grayscale image\n    r_channel = img_resized.copy()\n    g_channel = img_resized.copy()\n    b_channel = img_resized.copy()\n\n    # Merge the three channels to create an RGB image\n    rgb_image = Image.merge(\"RGB\", (r_channel, g_channel, b_channel))\n\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    rgb_image = transform(rgb_image)\n    \n    return rgb_image\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.868931Z","iopub.execute_input":"2023-11-29T09:04:25.869371Z","iopub.status.idle":"2023-11-29T09:04:25.888156Z","shell.execute_reply.started":"2023-11-29T09:04:25.869334Z","shell.execute_reply":"2023-11-29T09:04:25.887019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path=\"/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/HandwrittenData/images/test/001-equation000.png\"\n# Open the image file\n\nimg= preprocess(image_path)\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:25.889923Z","iopub.execute_input":"2023-11-29T09:04:25.890625Z","iopub.status.idle":"2023-11-29T09:04:26.098504Z","shell.execute_reply.started":"2023-11-29T09:04:25.890567Z","shell.execute_reply":"2023-11-29T09:04:26.097486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preprocess and Loading of data**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\n\n# Assuming your CSV file looks like this:\n# | image_name | formula       |\n# |------------|---------------|\n# | image1.png | \\alpha + \\beta|\n# | image2.png | \\gamma \\times \\delta|\n# ...\n\nclass CustomDataset(Dataset):\n    def __init__(self, csv_file, root_dir):\n        self.data = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n\n    def __len__(self):\n        return len(self.data)\n    def preprocess(image_path):\n        # Read the image using PIL\n        img = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n\n        # Resize the image to 224x224\n        img_resized = img.resize((224, 224))\n\n        # Create R, G, B channels by duplicating the grayscale image\n        r_channel = img_resized.copy()\n        g_channel = img_resized.copy()\n        b_channel = img_resized.copy()\n\n        # Merge the three channels to create an RGB image\n        rgb_image = Image.merge(\"RGB\", (r_channel, g_channel, b_channel))\n\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        rgb_image = transform(rgb_image)\n\n        return rgb_image\n        \n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n        img_name = self.data[\"image\"][idx]\n        img_path=root_dir+\"/\"+img_name\n        image=preprocess(img_path)\n        formula = torch.tensor(formula_to_tokens[idx])\n        return image, formula\n\n    \n\nroot_dir='/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/HandwrittenData/images/train'\nbatch_size=32\ntrain_dataset = CustomDataset(train_csv_path, root_dir)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:26.100336Z","iopub.execute_input":"2023-11-29T09:04:26.101002Z","iopub.status.idle":"2023-11-29T09:04:26.577522Z","shell.execute_reply.started":"2023-11-29T09:04:26.100963Z","shell.execute_reply":"2023-11-29T09:04:26.575906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in train_dataset:\n    print(row[0].shape,row[1].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:26.579418Z","iopub.execute_input":"2023-11-29T09:04:26.580162Z","iopub.status.idle":"2023-11-29T09:04:26.637502Z","shell.execute_reply.started":"2023-11-29T09:04:26.580121Z","shell.execute_reply":"2023-11-29T09:04:26.635848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i, batch in enumerate(train_loader):\n    img, formula = batch\n    print(img.shape,formula.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:26.639256Z","iopub.execute_input":"2023-11-29T09:04:26.640365Z","iopub.status.idle":"2023-11-29T09:04:27.565272Z","shell.execute_reply.started":"2023-11-29T09:04:26.640318Z","shell.execute_reply":"2023-11-29T09:04:27.563762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoder**","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Encoder(nn.Module):\n    def __init__(self):\n        super(Encoder, self).__init__()\n        # Define the layers for the CNN\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n        self.pool1 = nn.MaxPool2d(kernel_size=2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n        self.pool2 = nn.MaxPool2d(kernel_size=2)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=5)\n        self.pool3 = nn.MaxPool2d(kernel_size=2)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=5)\n        self.pool4 = nn.MaxPool2d(kernel_size=2)\n        self.conv5 = nn.Conv2d(256, 512, kernel_size=5)\n        self.pool5 = nn.MaxPool2d(kernel_size=2)\n        self.avgpool = nn.AvgPool2d(kernel_size=3, stride=1)  # Output size: 1x1x512\n\n    def forward(self, x):\n        # Forward pass through the CNN layers\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = self.pool4(F.relu(self.conv4(x)))\n        x = self.pool5(F.relu(self.conv5(x)))\n        x = self.avgpool(x)\n        x = x.squeeze()\n        x = x.unsqueeze(dim = 1)\n        return x\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:27.566851Z","iopub.execute_input":"2023-11-29T09:04:27.567247Z","iopub.status.idle":"2023-11-29T09:04:27.581199Z","shell.execute_reply.started":"2023-11-29T09:04:27.567218Z","shell.execute_reply":"2023-11-29T09:04:27.579789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder()\n\nfor i, batch in enumerate(train_loader):\n    img, formula = batch\n    print(encoder(img).shape)\n    break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:27.583185Z","iopub.execute_input":"2023-11-29T09:04:27.583658Z","iopub.status.idle":"2023-11-29T09:04:30.466447Z","shell.execute_reply.started":"2023-11-29T09:04:27.583616Z","shell.execute_reply":"2023-11-29T09:04:30.465032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decoder**","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n        super(Decoder, self).__init__()\n        \n        # Embedding layer\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(embedding_dim + 512, hidden_dim, batch_first=True)\n        \n        # Output layer\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x, hidden, cell,context_vec):\n        # x: input index-token\n        # hidden: tuple (hidden state, cell state)\n        \n        # Embedding\n        \n        embedded = self.embedding(x) #1x512\n        lstm_input=torch.cat((context_vec,embedded), dim = 2)#1x1024\n        \n        # LSTM\n        output,(hidden,cell) = self.lstm(lstm_input, (hidden,cell) )\n        \n        \n#         # Output layer\n        output = self.fc(output)\n        \n        return output, hidden,cell\n\n# Example instantiation\nvocab_size = len(tokens_set)  # Replace with the actual size of your vocabulary\nembedding_dim = 512\nhidden_dim = 512\n\n# Instantiate the decoder\ndecoder = Decoder(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_dim=hidden_dim)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:30.468550Z","iopub.execute_input":"2023-11-29T09:04:30.470119Z","iopub.status.idle":"2023-11-29T09:04:30.512347Z","shell.execute_reply.started":"2023-11-29T09:04:30.470054Z","shell.execute_reply":"2023-11-29T09:04:30.511022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FINAL CODE**","metadata":{}},{"cell_type":"code","source":"for i, batch in enumerate(train_loader):\n    img, formula = batch\n    print(img.shape,formula.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:30.513985Z","iopub.execute_input":"2023-11-29T09:04:30.514371Z","iopub.status.idle":"2023-11-29T09:04:31.400467Z","shell.execute_reply.started":"2023-11-29T09:04:30.514341Z","shell.execute_reply":"2023-11-29T09:04:31.398624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" class combined(nn.Module):\n        def __init__(self, encoder, decoder):\n            super(combined, self).__init__()\n            self.encoder = encoder\n            self.decoder = decoder\n        \n        def forward(self, images, formula):\n            print(\"image shape \",images.shape)\n            context_vec = encoder(images)#32x1x512  -- formuala- #32x88\n            print(\" context_vec shape \",context_vec.shape)\n            hidden=torch.zeros(1, context_vec.shape[0], context_vec.shape[2] )\n            cell=torch.zeros(1, context_vec.shape[0], context_vec.shape[2] )\n            #print(context_vec.shape)\n            input=formulas[:,0]\n            input=input.unsqueeze(1)#32x1\n            target_len = formulas.shape[1]\n            batch_size= formulas.shape[0]\n\n            result = torch.zeros(target_len, batch_size, vocab_size)\n            input = formulas[:, 0]\n            for t in range(0 , target_len):\n                input=input.unsqueeze(1)#32x1\n                #print(input.shape)\n                output, hidden,cell=decoder(input,hidden,cell,context_vec)\n                output = output.reshape((output.shape[0], output.shape[2]))\n                result[t] = output\n                teacher = random.random() < 0.5  \n                \n                if teacher == 0:\n                    input = output.argmax(dim = 1)\n                    #print(t,\" \",input.shape)\n                else:\n                    input = formulas[:, t]\n            return result\n        \n        def predict(self,images):\n            context_vec = encoder(images)#32x1x512  -- formuala- #32x88\n            hidden=torch.zeros(1, context_vec.shape[0], context_vec.shape[2] )\n            cell=torch.zeros(1, context_vec.shape[0], context_vec.shape[2] )\n            #print(context_vec.shape)\n        \n            target_len = 9999999\n            batch_size= context_vec.shape[0]\n            \n\n            result =[]\n            input = torch.full((batch_size,), 101)\n            for t in range(0 , target_len):\n                input=input.unsqueeze(1)#32x1\n                #print(input.shape)\n                output, hidden,cell=decoder(input,hidden,cell,context_vec)\n                output = output.reshape((output.shape[0], output.shape[2]))\n                myout=output.argmax(dim = 1)\n                print(t,myout[0])\n                result.append(myout[0])\n                if(myout[0] == 7):#112\n                    return result\n                input=myout\n            \n            result=torch.tensor(result)\n            result= torch.stack(result)\n            return result\n            \n            \n        \n            ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:31.403348Z","iopub.execute_input":"2023-11-29T09:04:31.403945Z","iopub.status.idle":"2023-11-29T09:04:31.422849Z","shell.execute_reply.started":"2023-11-29T09:04:31.403891Z","shell.execute_reply":"2023-11-29T09:04:31.421847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n# Assuming you have a SimpleLSTM model and other necessary components\n# (model, criterion, train_loader, etc.)\n\n# Define your optimizer\n\nFinal_model = combined(Encoder(), Decoder(vocab_size, 512, 512))\noptimizer = optim.Adam(Final_model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nno_of_epoch=10\ni=0\nfor epoch in range(no_of_epoch):\n    loss_epoch = 0\n    for batch_idx, (images, formulas) in enumerate(train_loader):\n        i=i+1\n        result=Final_model(images,formulas)\n       \n        print(\"result\",result.shape)\n        print(\"formula\",formulas.shape)\n        predicted_flat = result.reshape(result.shape[0]*result.shape[1],result.shape[2])\n        actual_flat = formulas.reshape(formulas.shape[0]*formulas.shape[1])\n        \n        print(\"predicted_flat\",predicted_flat.shape)\n        print(\"actual_flat\",actual_flat.shape)\n    \n        \n\n        # Calculate cross-entropy loss\n        #loss = nn.Cross_entropy(predicted_flat, actual_flat)\n        loss = criterion(predicted_flat, actual_flat)\n       # loss = F.cross_entropy(predicted_flat, actual_flat)\n  \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loss_epoch += loss.item()\n        if(i%100):\n            print(\"epoch \",epoch,i,\" \",loss,\" batch loss, \", loss_epoch/len(train_loader))\n     \n\ntorch.save(Final_model.state_dict(), 'your_model_checkpoint.pth')# saving the model state","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:07:53.937976Z","iopub.execute_input":"2023-11-29T09:07:53.938405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**loading the model and its state**","metadata":{}},{"cell_type":"code","source":"Final_model = combined(Encoder(), Decoder(vocab_size, 512, 512))\n\n# Load the saved model state dictionary\ncheckpoint_path = 'your_model_checkpoint.pth'  # Replace with the actual path\ncheckpoint = torch.load(checkpoint_path)\n\n# Load the state dictionary into your model\nFinal_model.load_state_dict(checkpoint)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:31.449431Z","iopub.status.idle":"2023-11-29T09:04:31.450525Z","shell.execute_reply.started":"2023-11-29T09:04:31.450126Z","shell.execute_reply":"2023-11-29T09:04:31.450158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = train_dataset[0]\nprint(row[0].shape,row[1].shape)\ntest_image=row[0]\ntest_formula=row[1]\n\ntest_image=test_image.repeat(batch_size, 1, 1,1)\n##result=Final_model\nprint(test_image.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:31.452497Z","iopub.status.idle":"2023-11-29T09:04:31.453683Z","shell.execute_reply.started":"2023-11-29T09:04:31.453262Z","shell.execute_reply":"2023-11-29T09:04:31.453306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_formula=Final_model.predict(test_image)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:31.455496Z","iopub.status.idle":"2023-11-29T09:04:31.456150Z","shell.execute_reply.started":"2023-11-29T09:04:31.455843Z","shell.execute_reply":"2023-11-29T09:04:31.455875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_formula)\nprint(\" \")\nprint(predicted_formuala)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:04:31.458950Z","iopub.status.idle":"2023-11-29T09:04:31.459584Z","shell.execute_reply.started":"2023-11-29T09:04:31.459360Z","shell.execute_reply":"2023-11-29T09:04:31.459384Z"},"trusted":true},"execution_count":null,"outputs":[]}]}